{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG data classification Guinnea Bissau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains experiments with an EEG dataset. The classes are Epilepsy: 0 or Control 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load dependences and setting output configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from npy files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify location of npy files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapath = '/media/windows-share/EEGs_Guinea-Bissau_np/'\n",
    "#datapath = '/media/sf_VBox_Shared/timeseries/EEGs_Guinea-Bissau_np/'#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data stored in 10 seconds at 128 Hertz corresponding to the experiment where the participant had the eyes closed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "condition = '_10seconds_closed.npy'\n",
    "X_train = np.load(datapath+'X_train'+condition)\n",
    "y_train = np.load(datapath+'y_train'+condition)\n",
    "X_val = np.load(datapath+'X_valid'+condition)\n",
    "y_val = np.load(datapath+'y_valid'+condition)\n",
    "X_test = np.load(datapath+'X_test'+condition)\n",
    "y_test = np.load(datapath+'y_test'+condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epilepsy': 0, 'Control': 1}\n"
     ]
    }
   ],
   "source": [
    "classlabels = list(set(y_train))\n",
    "mapclasses = {classlabels[i] : i for i in range(len(classlabels))}\n",
    "print(mapclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = np.array([mapclasses[c] for c in y_train], dtype='int')\n",
    "y_val = np.array([mapclasses[c] for c in y_val], dtype='int')\n",
    "y_test = np.array([mapclasses[c] for c in y_test], dtype='int')\n",
    "y_train_binary = to_categorical(y_train)\n",
    "y_val_binary = to_categorical(y_val)\n",
    "y_test_binary = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 1280, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "np.random.seed(1234)\n",
    "from keras.layers import Dense, Activation, Convolution1D, Lambda, \\\n",
    "    Convolution2D, Flatten, \\\n",
    "    Reshape, LSTM, Dropout, TimeDistributed, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_shape = X_train.shape\n",
    "class_number = y_train_binary.shape[1]\n",
    "dim_length = x_shape[1]  # number of samples in a time series\n",
    "dim_channels = x_shape[2]  # number of channels\n",
    "outputdim = class_number  # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filters = [50,50,40]\n",
    "fc_hidden_nodes = 3\n",
    "learning_rate=0.01\n",
    "regularization_rate=0.01\n",
    "weightinit = 'lecun_uniform' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(\n",
    "            input_shape=(dim_length, dim_channels),\n",
    "            mode=0, axis=2))\n",
    "for filter_number in filters:\n",
    "    model.add(Convolution1D(filter_number, 3, border_mode='same',\n",
    "                               W_regularizer=l2(regularization_rate),\n",
    "                                init=weightinit))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(output_dim=fc_hidden_nodes,\n",
    "                W_regularizer=l2(regularization_rate),\n",
    "                init=weightinit))  # Fully connected layer\n",
    "model.add(Activation('relu'))  # Relu activation\n",
    "model.add(Dense(output_dim=outputdim, init=weightinit))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"softmax\"))  # Final classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=learning_rate),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset_size = 60\n",
    "X_train_sub = X_train[:subset_size, :, :]\n",
    "y_train_sub = y_train_binary[:subset_size, :]\n",
    "nr_epochs = 10\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "60/60 [==============================] - 2s - loss: 3.5992 - acc: 0.8333 - val_loss: 1.3754 - val_acc: 0.5500\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 2s - loss: 3.7174 - acc: 0.7333 - val_loss: 1.0708 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 2s - loss: 3.7202 - acc: 0.8000 - val_loss: 0.7497 - val_acc: 0.4500\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 2s - loss: 3.5478 - acc: 0.9167 - val_loss: 1.1704 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 2s - loss: 3.4394 - acc: 0.9167 - val_loss: 0.8118 - val_acc: 0.6500\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 2s - loss: 3.2796 - acc: 0.9500 - val_loss: 0.8080 - val_acc: 0.7000\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 2s - loss: 3.1636 - acc: 0.9167 - val_loss: 0.7712 - val_acc: 0.7000\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 2s - loss: 2.9479 - acc: 0.9667 - val_loss: 0.8620 - val_acc: 0.4000\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 2s - loss: 2.7565 - acc: 0.9667 - val_loss: 0.8225 - val_acc: 0.6000\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 2s - loss: 2.6101 - acc: 0.9500 - val_loss: 0.8022 - val_acc: 0.5500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_sub, y_train_sub,\n",
    "                            nb_epoch=nr_epochs, batch_size=20,\n",
    "                            # see comment on subsize_set\n",
    "                            validation_data=(X_val, y_val_binary),\n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.46666665871938068, 0.55000001192092896, 0.58333333333333337, 0.75],\n",
       " 'loss': [2.3554260730743408,\n",
       "  2.9451981385548911,\n",
       "  3.3592026233673096,\n",
       "  3.4458752473195395],\n",
       " 'val_acc': [0.44999998807907104,\n",
       "  0.44999998807907104,\n",
       "  0.44999998807907104,\n",
       "  0.44999998807907104],\n",
       " 'val_loss': [8.8649530410766602,\n",
       "  8.8649530410766602,\n",
       "  8.8649530410766602,\n",
       "  8.5380735397338867]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Vict0rSch/deep_learning/tree/master/keras/recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
